{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практика 6: Атака по переносу (Transfer Attack) на модели ИИ\n",
        "# Чурсинов Герман ББМО-01-23\n",
        "\n",
        "## Изучить концепцию атаки по переносу, где противоречивые примеры, созданные для одной модели, используются для атаки на другую модель. Это задание требует создания нескольких моделей, генерации противоречивых примеров для одной модели и проверки их на другой модели.\n",
        "\n",
        "## Задачи:\n",
        "1. Загрузить несколько моделей, обученных на датасете MNIST.\n",
        "2. Изучить теоретические основы атаки по переносу.\n",
        "3. Реализовать атаку FGSM на одну модель и проверить, как противоречивые примеры влияют на другую модель.\n",
        "4. Оценить точность обеих моделей на противоречивых примерах и проанализировать переносимость атак.\n",
        "\n",
        "## Шаги выполнения:\n",
        "**Шаг 1: Загрузка и создание двух различных моделей**\n",
        "\n",
        "Создаем две модели на датасете MNIST: одну простую полносвязную сеть и одну свёрточную нейронную сеть (CNN).\n",
        "\n"
      ],
      "metadata": {
        "id": "4eCplKigSgxw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт всех необходимых для работы библиотек\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "NZgYPTQHYcPl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L686X7FnQv3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46b72a51-4484-4c68-bab4-cadce6c79397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.4279\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9630 - loss: 0.1221\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0794\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0587\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9856 - loss: 0.0456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 27ms/step - accuracy: 0.9117 - loss: 0.2972\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 26ms/step - accuracy: 0.9822 - loss: 0.0572\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 24ms/step - accuracy: 0.9904 - loss: 0.0318\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 24ms/step - accuracy: 0.9932 - loss: 0.0211\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 23ms/step - accuracy: 0.9958 - loss: 0.0135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Загрузка данных MNIST\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# Нормализация данных\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# Преобразование меток в one-hot encoding\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Модель 1: Простая полносвязная нейронная сеть\n",
        "model1 = Sequential([\n",
        " Flatten(input_shape=(28, 28)),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        " ])\n",
        "# Компиляция модели\n",
        "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Обучение модели\n",
        "model1.fit(train_images, train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model1.save('mnist_model1.h5')\n",
        "\n",
        "# Модель 2: Свёрточная нейронная сеть (CNN)\n",
        "model2 = Sequential([\n",
        " Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        " MaxPooling2D((2, 2)),\n",
        " Flatten(),\n",
        " Dense(128, activation='relu'),\n",
        " Dense(10, activation='softmax')\n",
        "])\n",
        "# Компиляция модели\n",
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Обучение модели\n",
        "model2.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=5)\n",
        "# Сохранение модели\n",
        "model2.save('mnist_model2.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 2: Теория атаки по переносу**\n",
        "\n",
        "Атака по переносу — это метод, при котором противоречивые примеры, созданные для одной модели, применяются к другой модели. Это возможно, потому что модели часто имеют схожие слабости и могут совершать одинаковые ошибки на определенных данных, даже если они обучены на разных архитектурах.\n",
        "\n",
        "В этом задании мы создадим противоречивые примеры для первой модели с помощью FGSM и затем проверим, насколько эти примеры могут атаковать вторую модель"
      ],
      "metadata": {
        "id": "GIBy_Ks1d87O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 3: Реализация атаки FGSM на первую модель**\n",
        "\n",
        "Мы применим атаку FGSM (Fast Gradient Sign Method) к первой модели, чтобы создать противоречивые примеры."
      ],
      "metadata": {
        "id": "3ydxBEyTeB90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для реализации FGSM атаки\n",
        "def fgsm_attack(image, epsilon, gradient):\n",
        "  # Применение знака градиента к изображению\n",
        "  perturbed_image = image + epsilon * np.sign(gradient)\n",
        "  perturbed_image = np.clip(perturbed_image, 0, 1) # Убедиться, что значения остаются в пределах [0, 1]\n",
        "  return perturbed_image\n",
        "\n",
        "# Вычисление градиента\n",
        "def generate_adversarial_example(model, image, label, epsilon):\n",
        "    # Превращаем изображение в формат, подходящий для модели\n",
        "    image = tf.convert_to_tensor(image.reshape((1, 28, 28, 1)))\n",
        "    if len(label.shape) > 1 and label.shape[1] > 1:\n",
        "        label = np.argmax(label) # ФИКС ОШИБКИ ИЗ ЗАДАНИЯ\n",
        "    label = tf.convert_to_tensor(label)\n",
        "\n",
        "    # Вычисление градиента\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(label[None], prediction)\n",
        "    gradient = tape.gradient(loss, image)\n",
        "    # Применяем FGSM\n",
        "    adversarial_image = fgsm_attack(image.numpy(), epsilon, gradient.numpy())\n",
        "    # Убедимся, что adversarial_image имеет правильную форму\n",
        "    return np.reshape(adversarial_image, (28, 28, 1))\n",
        "\n",
        "def generate_fgsm_adversarial(model, images, labels, epsilon):\n",
        "    adversarial_images = []\n",
        "    for i in range(len(images)):\n",
        "      image = tf.convert_to_tensor(images[i].reshape((1, 28, 28, 1)))\n",
        "      if len(labels[i].shape) > 1 and labels[i].shape[1] > 1:\n",
        "        label = np.argmax(labels[i]) # ФИКС ОШИБКИ ИЗ ЗАДАНИЯ\n",
        "      label = tf.convert_to_tensor(labels[i])\n",
        "      # Вычисление градиента\n",
        "      with tf.GradientTape() as tape:\n",
        "        tape.watch(image)\n",
        "        prediction = model(image)\n",
        "        loss = tf.keras.losses.categorical_crossentropy(labels[i][None], prediction)\n",
        "      gradient = tape.gradient(loss, image)\n",
        "      # Применяем FGSM\n",
        "      adversarial_image = np.reshape(fgsm_attack(image.numpy(), epsilon, gradient.numpy()), (28, 28, 1))\n",
        "      # Убедимся, что adversarial_image имеет правильную форму\n",
        "\n",
        "      adversarial_images.append(adversarial_image.reshape(28, 28))\n",
        "    adversarial_images = np.array(adversarial_images)\n",
        "    # Проверка формы\n",
        "    print(\"Shape of adversarial_images:\", adversarial_images.shape)\n",
        "    return adversarial_images\n",
        "\n",
        "\n",
        "# Генерация противоречивых примеров для первой модели\n",
        "epsilon = 0.1\n",
        "adversarial_images_model1 = generate_fgsm_adversarial(model1, test_images, test_labels, epsilon)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tEFMk6Ce4qC",
        "outputId": "5e70b95e-75f0-4355-a77e-bd28bf5201e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Шаг 4: Оценка противоречивых примеров на обеих моделях**\n",
        "\n",
        "Теперь мы проверим, как сильно атака PGD влияет на точность модели. Мы создадим набор противоречивых примеров и оценим производительность модели на этих данных."
      ],
      "metadata": {
        "id": "iReMLY7Xe8A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка первой модели на противоречивых примерах\n",
        "test_labels_argmax = np.argmax(test_labels, axis=1) # Преобразование onehot меток в целые числа\n",
        "loss1, acc1 = model1.evaluate(adversarial_images_model1, test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples: {acc1}')\n",
        "\n",
        "# Оценка второй модели на противоречивых примерах (перенос атаки)\n",
        "adversarial_images_model1_reshaped = adversarial_images_model1.reshape(-1, 28, 28, 1)\n",
        "loss2, acc2 = model2.evaluate(adversarial_images_model1_reshaped, test_labels)\n",
        "print(f'Accuracy of model2 on adversarial examples from model1: {acc2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoPB_DTZXoq2",
        "outputId": "88245745-3f17-4fd5-9c3e-955f508a4376"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0895 - loss: 6.6602\n",
            "Accuracy of model1 on adversarial examples: 0.11720000207424164\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9614 - loss: 0.1273\n",
            "Accuracy of model2 on adversarial examples from model1: 0.9660999774932861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Шаг 5: Анализ переносимости атак\n",
        "\n",
        "Проанализируйте, насколько успешно атака переносится с одной модели на другую. Вы можете заметить, что несмотря на различия в архитектуре, вторая модель также подвержена атаке, хотя и с другой степенью точности. Дополнительное задание (усложнение)\n",
        "\n",
        "Попробуйте создать противоречивые примеры для второй модели с помощью FGSM и проверьте их на первой модели.\n",
        "Оцените, какие модели более уязвимы к атакам по переносу, и предложите возможные решения для усиления защиты."
      ],
      "metadata": {
        "id": "mYD0Kg6FfUnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация противоречивых примеров для второй модели\n",
        "adversarial_images_model2 = generate_fgsm_adversarial(model2, test_images.reshape(-1, 28, 28, 1), test_labels, epsilon)\n",
        "\n",
        "# Оценка первой модели на противоречивых примерах второй модели\n",
        "loss3, acc3 = model1.evaluate(adversarial_images_model2.reshape(-1, 28, 28), test_labels)\n",
        "print(f'Accuracy of model1 on adversarial examples from model2: {acc3}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTv01mRpX7vx",
        "outputId": "60d07722-58d7-4974-80f2-c32b6b479eef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of adversarial_images: (10000, 28, 28)\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9537 - loss: 0.1492\n",
            "Accuracy of model1 on adversarial examples from model2: 0.9599000215530396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результаты:\n",
        "\n",
        "После выполнения этой практики ожидается, что вторая модель также будет уязвима к противоречивым примерам, созданным для первой модели, но с разной степенью эффективности. Вы также должны увидеть, что атака, созданная для одной модели, может работать на другой модели.\n",
        "И вот, в ходе выполнения задания мной была реализована атака по переносу, используя противоречивые примеры.\n",
        "\n",
        "Стоит отметить, что вторая модель оказалась ожидаемо уязвима к противоречивым примерам, которые я создал для первой модели, но оказалась уязвима с разной степенью эффективности. Также можно заметить, что атака, созданная для одной модели, может работать и на другой модели. На основании полученных результатов различные модели могут быть уязвимы к одним и тем же противоречивым примерам, даже если они обучены по-разному."
      ],
      "metadata": {
        "id": "Y4Xs9BHpX9R1"
      }
    }
  ]
}